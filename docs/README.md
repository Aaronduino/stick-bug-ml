# Documentation
This documentation covers each of the features in a typical workflow in order.

First, import the library:

```python
import ml_framework
from ml_framework.decorators import dataset, feature, model
```

You probably just want to copy and paste those exact import statements into your project, as they import the user facing side of the library.

In case you were wondering, the structure of the module looks like this (the `@` symbol is just decorative):
```
ml_framework
 | train(model_name, params)
 | evaluate(model_name, all_classes=None)
 | process(raw_data)
 | predict(model_name, processed_X)
 | decorators
    | @dataset(train_valid_test=(0.6, 0.2, 0.2))
    | @preprocess
    | @feature(name)
    | @model(name)
```


## Decorators

#### @dataset

This decorator is placed before a function that has no arguments, and returns a tuple of a pandas DataFrame (the `X`) and then a numpy array (the `y`)

The `train_valid_test` argument specifies how you would like to split up the training dataset.

Training dataset is used with ml models to train.
Validation data is used while tuning paramaters to make sure you aren't overfitting.
Testing data is never given to the models during training and its `y` values are only accessed by the framework when a call to `ml_framework.evaluate` is made.

In all, it should look like this:

```python
@dataset(train_valid_test=(0.6, 0.2, 0.2)) # define your train/test/validation data splits
def raw_dataset():
    # Some code to get the pandas DataFrame `X` and the numpy array `y`, maybe from a csv file
    return X, y
```

The framework runs the function, splits up the data, and then turns the raw_dataset name into something like a variable that holds the `X`. That is useful if you want to do something like this:

```python
print(my_dataset.head())
```

#### @preprocess

The @preprocess decorator is used to decorate a function that transforms the `X` values of the dataset

```python
@preprocess
def preprocessed_data(X):
    # Do some preprocessing here. Don't worry, the `X` argument is just a copy

    # (I often encode categorical columns here)

    return X # a pandas DataFrame

print(preprocessed_data.head()) # see note at @dataset documentation
```

Don't overthink it; it just replaces the dataset with its preprocessed counterpart.

#### @feature

This decorator is used to decorate functions that generate features for the dataset.

It optionally accepts an argument, its name. This name is added as a prefix to each of the columns in the DataFrame returned

Here's an example:
```python
@feature('text_length')
def pca_feature(X):
    return X['text'].apply(lambda text: len(text)) # it returns a pandas DataFrame

# let's preview
print(pca_feature.head()) # once again, the function's name becomes a variable holding its output
```

Optionally, the feature can be unnamed. This is useful in case you want to return specifically named columns.

Here's an example:

```python
@feature
def text_features(X):
  return pd.DataFrame({
    'word_count': X['text'].apply(lambda text: len(text.split(' '))),
    'char_count': X['text'].apply(lambda text: len(text))
  })
```

If that was confusing, here's an example that returns an identical DataFrame:

```python
@feature
def text_features(X):
  output = pd.DataFrame()
  output['word_count'] = X['text'].apply(lambda text: len(text.split(' ')))
  output['char_count'] = X['text'].apply(lambda text: len(text))
  return output
```

You can still get its evaluated output like before:

```python
print(text_features.head())
```

#### Models

**\@model:**

The @model decorator requires an argument that specifies the model's name.

The function that is decorated should return a tuple 3 different functions:
1. A function to define the model.
Parameters:
`num_columns`: the number of columns in the dataset (in `X`)
Returns:
`model`: the initialized model (which may be `None`)
2. A function to train the model.
Parameters:
`model`: the model generated by the `define` function
`params`: the parameters for training
`train`: a dictionary like {'X': train_X, 'y': train_y}
`validation`: a dictionary like {'X': validation_X, 'y': validation_y}
Returns:
`model`: the trained model
2. A function to make prediction from the trained model.
Parameters:
`model`: the trained model
`X`: the `X` values
Returns:
`predictions`: a numpy array of the predictions

For xgboost, it would look like this:
```python
import xgboost as xgb

@model('xgboost')
def xgboost_model():
    def define(num_columns):
        return None # xgboost models aren't pre-defined


    def train(model, params, train, validation):
        params['objective'] = 'binary:logistic' # Static parameters can be defined here
        params['eval_metric'] = 'logloss'

        d_train = xgb.DMatrix(train['X'], label=train['y'])
        d_valid = xgb.DMatrix(validation['X'], label=validation['y'])

        watchlist = [(d_train, 'train'), (d_valid, 'valid')]

        trained_model = xgb.train(params, d_train, 2000, watchlist, early_stopping_rounds=50, verbose_eval=10)

        return trained_model

    def predict(model, X):
        return model.predict(xgb.DMatrix(X))

    return define, train, predict
```

**train:**

Now you can train your model, trying out different parameters if your want:

```python
ml_framework.train('xgboost', {
    'max_depth': 7,
    'eta': 0.01
})
```

The library keeps the test data's ground truth values locked away so your models won't train on it.

**evaluate:**

After you train your model, have the framework evaluate it for you:

```python
logloss_score = ml_framework.evaluate('xgboost')
print(logloss_score)
```

The framework gives the model the `X` values through its `predict` function, and the framework uses the `y` values to calculate the log loss of the model's predictions.

**process & predict:**

Since this library is built with reality in mind, you can easily get predictions for new/real-life data:

```python
raw_X = pd.read_csv('2018_titanic_manifesto.csv') # It will probably sink, but we don't know who will survive
processed_X = ml_framework.process(raw_X) # Process the data
del raw_X

y = ml_framework.predict('xgboost', processed_X) # Make predictions

print(y)
```
