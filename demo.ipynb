{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stickbugml\n",
    "from stickbugml.decorators import dataset, preprocess, feature, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn.apionly as sns\n",
    "import pandas as pd\n",
    "\n",
    "@dataset(train_valid_test=(0.6, 0.2, 0.2))\n",
    "def raw_dataset():\n",
    "    titanic_dataset = sns.load_dataset('titanic')\n",
    "\n",
    "    # Drop NaN rows for simplicity\n",
    "    titanic_dataset.dropna(inplace=True)\n",
    "\n",
    "    # Extract X and y\n",
    "    X = titanic_dataset.drop('survived', axis=1)\n",
    "    y = titanic_dataset['survived']\n",
    "    return X, y\n",
    "\n",
    "# my_dataset is now a variable that holds the X values of the evaluated function\n",
    "# (the test data's ground truth is locked away to prevent accidentially fitting to it)\n",
    "raw_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@preprocess\n",
    "def preprocessed_dataset(X):\n",
    "    # Encode categorical columns\n",
    "    categorical_column_names = [\n",
    "        'sex', 'embarked', 'class',\n",
    "        'who', 'adult_male', 'deck',\n",
    "        'embark_town', 'alive', 'alone'\n",
    "    ]\n",
    "\n",
    "    X = pd.get_dummies(X,\n",
    "                       columns=categorical_column_names,\n",
    "                       prefix=categorical_column_names)\n",
    "\n",
    "    return X\n",
    "\n",
    "preprocessed_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "import numpy as np\n",
    "\n",
    "@feature('pca')\n",
    "def pca_feature(X):\n",
    "    pca = decomposition.PCA(n_components=3)\n",
    "    pca.fit(X)\n",
    "    pca_out = pca.transform(X)\n",
    "\n",
    "    pca_out = np.transpose(pca_out, (1, 0))\n",
    "    return pd.DataFrame(pca_out)\n",
    "\n",
    "pca_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "@model('xgboost')\n",
    "def xgboost_model():\n",
    "    def define(num_columns):\n",
    "        return None # xgboost models are not pre-defined\n",
    "    \n",
    "    def train(model, params, train, validation):\n",
    "        params['objective'] = 'binary:logistic'\n",
    "        params['eval_metric'] = 'logloss'\n",
    "        \n",
    "        d_train = xgb.DMatrix(train['X'], label=train['y'])\n",
    "        d_valid = xgb.DMatrix(validation['X'], label=validation['y'])\n",
    "\n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "        return xgb.train(params, d_train, 10000, watchlist, early_stopping_rounds=50, verbose_eval=200)\n",
    "    \n",
    "    def predict(model, X):\n",
    "        return model.predict(xgb.DMatrix(X))\n",
    "    \n",
    "    return define, train, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stickbugml.train('xgboost', {\n",
    "    'max_depth': 7,\n",
    "    'eta': 0.005\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stickbugml.evaluate('xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "@model('keras_nn')\n",
    "def keras_nn_model():\n",
    "    def define(num_columns):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(64, input_dim=num_columns, activation='relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='rmsprop',\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    \n",
    "    def train(model, params, train, validation):\n",
    "        model.fit(train['X'].values, train['y'].values,\n",
    "                  epochs=50,\n",
    "                  batch_size=5)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def predict(model, X):\n",
    "        return model.predict(X.values)\n",
    "    \n",
    "    return define, train, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stickbugml.train('keras_nn', {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stickbugml.evaluate('keras_nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
